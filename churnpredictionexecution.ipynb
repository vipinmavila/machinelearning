{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 14 22:00:36 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/pyparsing.py:2681: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile( self.reString )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-14 22:01:11.894262\n",
      "CPU times: user 861 ms, sys: 189 ms, total: 1.05 s\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    " %%time\n",
    "import datetime\n",
    "import shutil\n",
    "import time\n",
    "print(time.asctime())\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import autosklearn.classification\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from autosklearn.constants import *\n",
    "from autosklearn import metrics\n",
    "import warnings\n",
    "import os\n",
    "import multiprocessing\n",
    "from autosklearn.metrics import make_scorer\n",
    "from autosklearn.metrics import roc_auc\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "print(start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-14 22:01:11.901018\n",
      "CPU times: user 123 µs, sys: 0 ns, total: 123 µs\n",
      "Wall time: 85.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Constant values\n",
    "data_dir = \"/home/fedora/programs/hackathon/\"\n",
    "target_file = \"orange_large_train_churn.labels\"\n",
    "NUMROWS = 50000\n",
    "SELROWS = 25000\n",
    "memory_limit       = 24576##20480  ##18432  ## 18GB RAM  \n",
    "time_to_run_algo   = 86400  ##14400  4hrs ##43200  ## 12hrs\n",
    "time_to_run_ensemble = 43200 ## 12 hrs  \n",
    "tmp_folder = '/tmp/autosklearn_parallel_example_tmp'\n",
    "output_folder = '/tmp/autosklearn_parallel_example_out'\n",
    "feat_extract_txt   = \"kdd2009\"\n",
    "dataset_name = \"kdd_ds\"\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train target shape\n",
      " (7435, 1)\n",
      "\n",
      "test target shape\n",
      " (25000,)\n",
      "\n",
      "Input train data shape\n",
      " (7435, 2907)\n",
      "\n",
      "Input test data shape\n",
      " (25000, 2907)\n",
      "2018-11-14 22:01:15.220183\n"
     ]
    }
   ],
   "source": [
    "## Target churn\n",
    "fulltarget_df = pd.read_csv(data_dir+target_file, header=None, squeeze=True, skiprows=0, nrows=NUMROWS)\n",
    "\n",
    "\n",
    "selrows = [x for x in range (0,SELROWS)]\n",
    "selrows.sort() \n",
    "\n",
    "##traintarget_df = fulltarget_df.loc[selrows]\n",
    "##print(\"\\ntrain target shape\\n\", traintarget_df.shape)\n",
    "#print(\"\\ntrain target \\n\", traintarget_df)\n",
    "traintarget_df  = pd.read_pickle(\"rusytrainpickle\")\n",
    "print(\"\\ntrain target shape\\n\", traintarget_df.shape)\n",
    "\n",
    "## target churn for testing\n",
    "fulltarget_df.drop(fulltarget_df.index[selrows], inplace=True)\n",
    "testtarget_df = pd.Series()\n",
    "testtarget_df = fulltarget_df\n",
    "print(\"\\ntest target shape\\n\", testtarget_df.shape)\n",
    "\n",
    "\n",
    "## Input data for training\n",
    "train_df  = pd.read_pickle(\"rustrainpickle\")\n",
    "print(\"\\nInput train data shape\\n\", train_df.shape)\n",
    "\n",
    "## Fill NaN with 0's\n",
    "train_df.fillna(0)\n",
    "\n",
    "## Input data for testing\n",
    "test_df  = pd.read_pickle(\"rustestpickle\")\n",
    "print(\"\\nInput test data shape\\n\", test_df.shape)\n",
    "\n",
    "## Fill NaN with 0's\n",
    "test_df.fillna(0)\n",
    "\n",
    "\n",
    "X_train = train_df\n",
    "y_train = traintarget_df\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_suffix = str(start)\n",
    "\n",
    "# File prefixes / suffixes\n",
    "for ch in [\" \", \":\", \"-\"]:\n",
    "    time_suffix = time_suffix.replace(ch, \"\")\n",
    "\n",
    "f_name_prefix = \"automl_model_\" + feat_extract_txt\n",
    "f_name_suffix = \"_\" + time_suffix + \".txt\"\n",
    "temp_log_str  = \"temp_log_\"\n",
    "\n",
    "f_res_name = f_name_prefix + \"final_results\" + f_name_suffix\n",
    "\n",
    "##recall = make_scorer('recall', recall_score, labels = [-1,1], pos_label = 1, average = \"binary\")\n",
    "\n",
    "def get_spawn_classifier(X_train, y_train):\n",
    "    def spawn_classifier(seed, dataset_name):\n",
    "        \"\"\"Spawn a subprocess.\n",
    "\n",
    "        auto-sklearn does not take care of spawning worker processes. This\n",
    "        function, which is called several times in the main block is a new\n",
    "        process which runs one instance of auto-sklearn.\n",
    "        \"\"\"\n",
    "\n",
    "        # Use the initial configurations from meta-learning only in one out of\n",
    "        # the four processes spawned. This prevents auto-sklearn from evaluating\n",
    "        # the same configurations in four processes.\n",
    "        if seed == 0:\n",
    "            initial_configurations_via_metalearning = 25\n",
    "            smac_scenario_args = {}\n",
    "        else:\n",
    "            initial_configurations_via_metalearning = 0\n",
    "            smac_scenario_args = {'initial_incumbent': 'RANDOM'}\n",
    "\n",
    "        # Arguments which are different to other runs of auto-sklearn:\n",
    "        # 1. all classifiers write to the same output directory\n",
    "        # 2. shared_mode is set to True, this enables sharing of data between\n",
    "        # models.\n",
    "        # 3. all instances of the AutoSklearnClassifier must have a different seed!\n",
    "        automl = AutoSklearnClassifier(\n",
    "            time_left_for_this_task=time_to_run_algo, # sec., how long should this seed fit process run\n",
    "            ml_memory_limit=memory_limit, # MB, memory limit imposed on each call to a ML algorithm\n",
    "            include_preprocessors=[\"no_preprocessing\"],\n",
    "            exclude_preprocessors=None,\n",
    "            include_estimators = [\"random_forest\"],\n",
    "            shared_mode=True, # tmp folder will be shared between seeds\n",
    "            tmp_folder=tmp_folder,\n",
    "            output_folder=output_folder,\n",
    "            delete_tmp_folder_after_terminate=False,\n",
    "            ensemble_size=0, # ensembles will be built when all optimization runs are finished\n",
    "            initial_configurations_via_metalearning=initial_configurations_via_metalearning,\n",
    "            seed=seed,\n",
    "            smac_scenario_args=smac_scenario_args,\n",
    "        )\n",
    "        \n",
    "        automl.fit(X_train, y_train, metric=metrics.roc_auc, dataset_name=dataset_name)\n",
    "        \n",
    "        f_name = f_name_prefix + temp_log_str + str(seed) + f_name_suffix\n",
    "        \n",
    "        with open (f_name, \"a\") as ar:\n",
    "            ar.write(\"\\n\\n------------------AUTOML_SEED: \" + str(seed) + \"------------------------\")\n",
    "            ar.write (\"\\n\\n-----------------------cv_results--------------------\\n\\n\")\n",
    "            for item in automl.cv_results_:\n",
    "                ar.write (str (item) + \"\\n\")\n",
    "\n",
    "            ar.write (\"\\n\\n--------------sprint_statistics-----------------------\\n\\n\")\n",
    "            ar.write (str (automl.sprint_statistics()) + \"\\n\")\n",
    "            \n",
    "    print(datetime.datetime.now())    \n",
    "    return spawn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-14 22:01:24.365028\n",
      "[WARNING] [2018-11-15 00:34:13,045:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 00:34:13,045:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 01:02:59,240:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 01:02:59,240:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 05:44:56,956:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 05:44:56,956:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 07:53:00,124:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 07:53:00,124:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 08:30:58,315:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 08:30:58,315:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 08:51:57,827:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 08:51:57,827:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 13:44:03,762:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 13:44:03,762:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 16:18:36,272:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 16:18:36,272:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 16:25:39,698:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 16:25:39,698:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 19:15:24,692:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 19:15:24,692:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 19:16:42,141:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-11-15 19:16:42,141:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "Starting to build an ensemble!\n",
      "CPU times: user 26.6 s, sys: 5.34 s, total: 31.9 s\n",
      "Wall time: 1d 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    for dir in [tmp_folder, output_folder]:\n",
    "        try:\n",
    "            shutil.rmtree(dir)\n",
    "        except OSError as e:\n",
    "            pass\n",
    "\n",
    "    processes = []\n",
    "    spawn_classifier = get_spawn_classifier(X_train, y_train)\n",
    "    \n",
    "    for i in range(7): # set this at roughly half of your cores\n",
    "        p = multiprocessing.Process(target=spawn_classifier, args=(i, dataset_name))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "        \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print('Starting to build an ensemble!')\n",
    "    automl = AutoSklearnClassifier(\n",
    "        time_left_for_this_task=time_to_run_ensemble,\n",
    "        ml_memory_limit=memory_limit,\n",
    "        shared_mode=True,\n",
    "        ensemble_size=50,\n",
    "        ensemble_nbest=200,\n",
    "        tmp_folder=tmp_folder,\n",
    "        output_folder=output_folder,\n",
    "        initial_configurations_via_metalearning=0,\n",
    "        seed=1,\n",
    "    )\n",
    "\n",
    "    # Both the ensemble_size and ensemble_nbest parameters can be changed now if\n",
    "    # necessary\n",
    "    automl.fit_ensemble(\n",
    "        y_train,\n",
    "        task=BINARY_CLASSIFICATION,\n",
    "        metric=metrics.roc_auc,\n",
    "        precision='64',\n",
    "        dataset_name=dataset_name\n",
    "    )\n",
    "    \n",
    "    pickle.dump(file=open(\"automl1mp_model\" + \".pkl\", \"wb\"), obj=automl)\n",
    "    \n",
    "    with open(f_res_name, \"a\") as ar:\n",
    "        for file in os.listdir():\n",
    "            if ((f_name_prefix+temp_log_str) in file):\n",
    "                with open(file, \"r\") as fp:\n",
    "                    ar.write (fp.read())\n",
    "                    ar.write(\"\\n\")\n",
    "                os.remove(file)\n",
    "            \n",
    "        ar.write (\"\\n\\n------------------show_models----------------------------\\n\\n\")\n",
    "        ar.write (str (automl.show_models()) + \"\\n\")    \n",
    "\n",
    "        ar.write (\"\\n\\n------------------params----------------------------\\n\\n\")\n",
    "        ar.write (str (automl.get_params()) + \"\\n\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "estchurntest\n",
      " 0       -1\n",
      "1       -1\n",
      "2       -1\n",
      "3       -1\n",
      "4       -1\n",
      "5       -1\n",
      "6       -1\n",
      "7       -1\n",
      "8       -1\n",
      "9       -1\n",
      "10      -1\n",
      "11      -1\n",
      "12      -1\n",
      "13      -1\n",
      "14       1\n",
      "15       1\n",
      "16      -1\n",
      "17      -1\n",
      "18      -1\n",
      "19      -1\n",
      "20      -1\n",
      "21      -1\n",
      "22      -1\n",
      "23      -1\n",
      "24      -1\n",
      "25      -1\n",
      "26      -1\n",
      "27      -1\n",
      "28      -1\n",
      "29      -1\n",
      "        ..\n",
      "24970   -1\n",
      "24971   -1\n",
      "24972   -1\n",
      "24973   -1\n",
      "24974   -1\n",
      "24975   -1\n",
      "24976    1\n",
      "24977    1\n",
      "24978    1\n",
      "24979   -1\n",
      "24980   -1\n",
      "24981   -1\n",
      "24982   -1\n",
      "24983   -1\n",
      "24984   -1\n",
      "24985    1\n",
      "24986   -1\n",
      "24987   -1\n",
      "24988    1\n",
      "24989   -1\n",
      "24990   -1\n",
      "24991   -1\n",
      "24992   -1\n",
      "24993   -1\n",
      "24994    1\n",
      "24995    1\n",
      "24996   -1\n",
      "24997   -1\n",
      "24998   -1\n",
      "24999   -1\n",
      "Length: 25000, dtype: int64\n",
      "CPU times: user 2min 39s, sys: 18.6 s, total: 2min 58s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Predictions\n",
    "predictions = []\n",
    "predictions.append(automl.predict(test_df))\n",
    "\n",
    "## Estimated churn from test\n",
    "estchurntest = np.array(predictions).sum(axis=0)\n",
    "estchurntest = [-1 if item < 0 else 1 for item in estchurntest]\n",
    "estchurntest = pd.Series(estchurntest)\n",
    "print(\"\\nestchurntest\\n\", estchurntest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Precision (micro) = 0.85156\n",
      "\n",
      "\n",
      "Recall (micro) = 0.85156\n",
      "\n",
      "\n",
      "F1 (micro) = 0.85156\n",
      "\n",
      "\n",
      "Precision (macro) = 0.5695213732934564\n",
      "\n",
      "\n",
      "Recall (macro) = 0.6111109457713785\n",
      "\n",
      "\n",
      "F1 (macro) = 0.5813266023677893\n",
      "\n",
      "\n",
      "Precision (weighted) = 0.889346943080849\n",
      "\n",
      "\n",
      "Recall (weighted) = 0.85156\n",
      "\n",
      "\n",
      "F1 (weighted) = 0.8685261097542553\n",
      "\n",
      "\n",
      "Precision (None) = [0.94409456 0.19494819]\n",
      "\n",
      "\n",
      "Recall (None) = [0.89271998 0.32950192]\n",
      "\n",
      "\n",
      "F1 (None) = [0.91768881 0.24496439]\n",
      "\n",
      "\n",
      "confusion_matrix = [[20687  2486]\n",
      " [ 1225   602]]\n",
      "CPU times: user 274 ms, sys: 9.83 ms, total: 283 ms\n",
      "Wall time: 106 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Check accuracy\n",
    "avg_vals = [\"micro\", \"macro\", \"weighted\", None]\n",
    "\n",
    "with open (\"automl_results.txt\", \"a\") as ar:\n",
    "\n",
    "    ar.write (\"------------------Scores----------------------------\\n\\n\")\n",
    "    \n",
    "    for avg_val in avg_vals:\n",
    "    \n",
    "        str_val = (\"\\n\\nPrecision (\" \n",
    "                   + str(avg_val)\n",
    "                   + \") = \" \n",
    "                   + str(precision_score(y_true=testtarget_df, y_pred=estchurntest, average=avg_val)))\n",
    "\n",
    "        print (str_val)\n",
    "        ar.write (str_val)\n",
    "        \n",
    "        str_val = (\"\\n\\nRecall (\" \n",
    "                   + str(avg_val) \n",
    "                   + \") = \" \n",
    "                   + str(recall_score(y_true=testtarget_df, y_pred=estchurntest, average=avg_val)))\n",
    "\n",
    "        print (str_val)\n",
    "        ar.write (str_val)\n",
    "        \n",
    "        str_val = (\"\\n\\nF1 (\" \n",
    "                   + str(avg_val) \n",
    "                   + \") = \" \n",
    "                   + str(f1_score(y_true=testtarget_df, y_pred=estchurntest, average=avg_val)))\n",
    "\n",
    "        print (str_val)\n",
    "        ar.write (str_val)\n",
    "        \n",
    "    str_val = (\"\\n\\nconfusion_matrix\"\n",
    "                   + \" = \" \n",
    "                   + str(confusion_matrix(y_true=testtarget_df, y_pred=estchurntest)))\n",
    "    print (str_val)\n",
    "    ar.write (str_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
